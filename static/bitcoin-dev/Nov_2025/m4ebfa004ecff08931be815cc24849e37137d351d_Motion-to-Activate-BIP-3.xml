<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <id>1</id>
  <title>Motion to Activate BIP 3</title>
  <updated>2025-11-19T02:52:24.544804+00:00</updated>
  <author>
    <name>Greg Maxwell 2025-11-18 04:26:00+00:00</name>
  </author>
  <generator uri="https://lkiesow.github.io/python-feedgen" version="0.9.0">python-feedgen</generator>
  <entry>
    <id>1</id>
    <title>Motion to Activate BIP 3</title>
    <updated>2025-11-19T02:52:24.544842+00:00</updated>
    <link href="https://gnusha.org/pi/bitcoindev/3a66dbbe9a9c46566c8a9a16ccb1cc91@dtrt.org/T/#m4ebfa004ecff08931be815cc24849e37137d351d" rel="alternate"/>
    <summary>The discussion revolves around the adequacy of AI disclosure norms, especially in light of concerns such as LLM psychosis and various influence or judgement compromising effects that have been well documented. The opinion expressed suggests that the current level of disclosure may be insufficiently robust to address these concerns. There is a clear stance against further diluting the already established text concerning AI disclosures. This perspective underscores the need for maintaining, if not enhancing, the transparency and comprehensiveness of disclosures related to AI's potential risks and uncertainties. The mention of specific phenomena like LLM psychosis highlights the complex and potentially unpredictable impacts AI can have, emphasizing the importance of clear communication about these technologies' capabilities and limitations.</summary>
    <published>2025-11-18T04:26:00+00:00</published>
  </entry>
</feed>
